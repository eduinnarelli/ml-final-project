{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bertimbau.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNZUtUN483qmwLYfWp/+fJ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BHjX9hpbZcLc"},"source":["## **Projeto Final**: Aprendizado de Máquina MC886\r\n","\r\n","# **Detecção de Comentários Tóxicos em Português do Brasil:** Bertimbau\r\n","\r\n","Universidade de Campinas (UNICAMP), Instituto da Computação (IC)\r\n","\r\n","Prof. Sandra Avila, 2s2020\r\n","\r\n","**Grupo**:\r\n","- Eduardo Barros Innarelli (170161)\r\n","- João Pedro Congio Martins (176117)\r\n","- Pedro Alan Tapia Ramos (185531)"]},{"cell_type":"markdown","metadata":{"id":"eCbpzMc_bezn"},"source":["---\r\n","\r\n","Se você estiver usando o Google Colab, conecte com o Google Drive para ter acesso aos datasets:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrZNAz2TbcIi","executionInfo":{"status":"ok","timestamp":1610471221751,"user_tz":180,"elapsed":2330,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"b3cd4fdb-73bb-4354-c19f-5db57038f8a3"},"source":["from google.colab import drive\r\n","\r\n","# Isso solicitará autorização\r\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5ZePZUsbitq","executionInfo":{"status":"ok","timestamp":1610471224600,"user_tz":180,"elapsed":1412,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"06251c22-d4cb-4a97-c5c4-774bfe686abe"},"source":["# Vá até a pasta do projeto (depende da onde está salva no seu Drive)\r\n","% cd '/content/drive/My Drive/[MC886] Projeto Final/'\r\n","! ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/[MC886] Projeto Final\n","bertimbau.ipynb\t\t docs\t     nbsvm_baseline.ipynb  __pycache__\n","build_nbsvm_pipeline.py  model_save  nbsvm-model.joblib    split_dataset.py\n","data\t\t\t nbsvm\t     pretrained-bert\t   tokenizer.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7W9Re2tublxd"},"source":["---\r\n","\r\n","## **Dependências**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwgmq1zcraW-","executionInfo":{"status":"ok","timestamp":1610471232145,"user_tz":180,"elapsed":4703,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"78030cc4-79d8-407c-99ec-ef31691a71c3"},"source":["# Instalar a lib transformers\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"68GsxMZ8bn5v","executionInfo":{"status":"ok","timestamp":1610478358268,"user_tz":180,"elapsed":1506,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["# Bibliotecas utilizadas\r\n","import os\r\n","import random\r\n","import time\r\n","import datetime\r\n","import numpy as np\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn.metrics import classification_report, confusion_matrix\r\n","\r\n","# Pacotes de pré-processamento e treinamento\r\n","import torch\r\n","from torch.utils.data import (TensorDataset, DataLoader, RandomSampler, \r\n","                              SequentialSampler, random_split)\r\n","from transformers import (BertTokenizer, BertForSequenceClassification, AdamW, \r\n","                          BertConfig, get_linear_schedule_with_warmup)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"barv1ooikVWo","executionInfo":{"status":"ok","timestamp":1610471240654,"user_tz":180,"elapsed":1106,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"df043017-d499-4c8d-f0ce-e7ab4365ed2c"},"source":["# Pedir para pytorch usar a GPU, se possível\r\n","if torch.cuda.is_available():    \r\n","    device = torch.device(\"cuda\")\r\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n","else:\r\n","    print('No GPU available, using the CPU instead.')\r\n","    device = torch.device(\"cpu\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ntXFvY7fbtr9"},"source":["## **Pré-processamento**\r\n","\r\n","Usamos a mesma estratégia do artigo base de agregar as classes de ofensa em uma única e classificar um tweet como tóxico se ao menos uma pessoa o anotou como tal em alguma das categorias.\r\n","\r\n","> \"In this paper, we consider the least restrictive case,\r\n","where if at least one annotator marked any offence\r\n","category in an example, the example is positive for\r\n","toxicity. Likewise, if a tweet was not tagged in any\r\n","of these categories, it is considered non-toxic. We\r\n","believe that it is essential that if any person feels\r\n","uncomfortable with a post, it should be flagged as\r\n","having a certain degree of toxicity. Therefore, a\r\n","model built with this data must be able to identify\r\n","offensive posts, even for a specific group of people.\"\r\n"]},{"cell_type":"code","metadata":{"id":"Y2AobHayb1-V","executionInfo":{"status":"ok","timestamp":1610471244350,"user_tz":180,"elapsed":1053,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["# Carregar dataset\r\n","told_br = pd.read_csv(\"data/ToLD-BR.csv\")\r\n","\r\n","# Agregar classes de comentários ofensivos\r\n","told_br['label'] = told_br[['homophobia', \r\n","                            'obscene',\r\n","                            'insult',\r\n","                            'misogyny',\r\n","                            'xenophobia']].agg('sum', axis=1)\r\n","\r\n","# Converter em classificação binária (1 é tóxico, 0 não é tóxico)\r\n","told_br.loc[told_br['label'] >= 1, 'label'] = 1\r\n","\r\n","# Salvar em arrays numpy\r\n","texts = told_br.text.values\r\n","labels = told_br.label.values"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CjhgjvwW8M9"},"source":["O texto a ser enviado para o BERT deve ser dividido em tokens. O tokenizador do BERT já trata de incluir os tokens especiais que o modelo requere, de mapear os tokens e de truncar os textos. "]},{"cell_type":"code","metadata":{"id":"4BOSkvFSYsg8","executionInfo":{"status":"ok","timestamp":1610471251697,"user_tz":180,"elapsed":1169,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["# Carregar tokenizer\r\n","tokenizer = BertTokenizer.from_pretrained('pretrained-bert', do_lower_case=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYTam50_KAZG","executionInfo":{"status":"ok","timestamp":1610471273867,"user_tz":180,"elapsed":14651,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"99cf3b9f-5b66-41df-80d4-d7a8dcdb154f"},"source":["input_ids = []\r\n","attention_masks = []\r\n","\r\n","for text in texts:\r\n","  # `encode_plus` vai:\r\n","  #   (1) Tokenizar o texto.\r\n","  #   (2) Prefixar o token `[CLS]` no início.\r\n","  #   (3) Anexar o token `[SEP]` no fim.\r\n","  #   (4) Mapear cada token ao seu ID.\r\n","  #   (5) Truncar ou preencher o texto até `max_length`.\r\n","  #   (6) Criar máscaras de atenção para tokens [PAD].\r\n","  encoded_dict = tokenizer.encode_plus(\r\n","                    text,\r\n","                    add_special_tokens = True,   \r\n","                    max_length = 188, # maior texto tem 188 tokens\r\n","                    padding = 'max_length',\r\n","                    return_attention_mask = True,\r\n","                    return_tensors = 'pt',\r\n","                )\r\n","  \r\n","  # Adicionar tokens codificados\r\n","  input_ids.append(encoded_dict['input_ids'])\r\n","\r\n","  # Adicionar máscaras de atenção (diferencia padding de não padding)\r\n","  attention_masks.append(encoded_dict['attention_mask'])\r\n","\r\n","# Converter listas em tensores\r\n","input_ids = torch.cat(input_ids, dim=0)\r\n","attention_masks = torch.cat(attention_masks, dim=0)\r\n","labels = torch.tensor(labels)\r\n","\r\n","# Imprimir texto 0 como sequência de ID's\r\n","print('Original: ', texts[0])\r\n","print('Token IDs:', input_ids[0])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Original:  Meu nivel de amizade com isis é ela ter meu insta e eu ter o dela, e quando eu penso que não ela manda mensagem “ falano otario ta falando dnv no insta”\n","Token IDs: tensor([  101,  7343,   149,  4812,   125,  8286,   170,   847,   145,   122,\n","          740,   370,  7343,  2861,   122,  2779,   370,   146,  3914,   117,\n","          122,   625,  2779,  4174, 22280,   179,   229, 22280,   740,  3497,\n","         6947,  1112,  3887,   300,   146,   578,   247,   316, 12402,   121,\n","        22285, 22292,   202,  2861, 22354,   102,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WTetgc88b0Ne"},"source":["Agora, dividimos o dataset em treino, validação e teste.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJ47UfVNb5mv","executionInfo":{"status":"ok","timestamp":1610471300406,"user_tz":180,"elapsed":931,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"ea5b16d3-19ad-4ae7-ffaa-f3b09d385d6f"},"source":["# Combinar inputs em um TensorDataset\r\n","dataset = TensorDataset(input_ids, attention_masks, labels)\r\n","\r\n","# Calcular número de exemplos que cada divisão terá\r\n","train_size = int(0.8 * len(dataset)) # 80%\r\n","val_size = int(0.1 * len(dataset)) # 10%\r\n","test_size = val_size # 10%\r\n","\r\n","# Divide dataset aleatoriamente\r\n","train_dataset, val_dataset, test_dataset = random_split(\r\n","    dataset, [train_size, val_size, test_size])\r\n","\r\n","print('{:>5,} training samples'.format(train_size))\r\n","print('{:>5,} validation samples'.format(val_size))\r\n","print('{:>5,} test samples'.format(test_size))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["16,800 training samples\n","2,100 validation samples\n","2,100 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"20IVvfaC3p0j"},"source":["Finalmente, iterator são criados para os conjuntos de treino, validação e teste usando a classe `DataLoader`. Isso ajuda a economizar memória durante o treinamento, pois evita com que todo o dataset seja carregado na memória ao contrário de um loop comum. "]},{"cell_type":"code","metadata":{"id":"KL8lNV6JYwD-","executionInfo":{"status":"ok","timestamp":1610471303352,"user_tz":180,"elapsed":1151,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["# O DataLoader precisa saber o tamanho do batch de treinamento, então \r\n","# especificamos aqui. Para treinar o BERT em uma tarefa específica, os autores\r\n","# recomendam um tamanho de 16 ou 32.\r\n","batch_size = 16\r\n","\r\n","# Criar DataLoader para conj. de treino\r\n","train_dataloader = DataLoader(\r\n","  train_dataset,\r\n","  sampler = RandomSampler(train_dataset), # selecionar aleatoriamente\r\n","  batch_size = batch_size\r\n",")\r\n","\r\n","# Criar DataLoader para conj. de validação\r\n","validation_dataloader = DataLoader(\r\n","  val_dataset, \r\n","  sampler = SequentialSampler(val_dataset), # selecionar sequencialmente\r\n","  batch_size = batch_size\r\n",")\r\n","\r\n","# Criar DataLoader para conj. de teste\r\n","test_dataloader = DataLoader(\r\n","  test_dataset, \r\n","  sampler = SequentialSampler(test_dataset), # selecionar sequencialmente\r\n","  batch_size = batch_size\r\n",")"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gd_z91Jab9xP"},"source":["## **Treinamento**\r\n","\r\n","A biblioteca `transformers` inclui uma série de interfaces projetadas para diferentes tarefas de ILP. Usamos a classe `BertForSequenceClassification`, que inclui uma camada de classificação no modelo BERT pré-treinado passado por parâmetro, no nosso caso o BERTimbau. Assim, carregamos o modelo e instanciamos alguns hiperparâmetros."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_pn7ZQocA23","executionInfo":{"status":"ok","timestamp":1610471314789,"user_tz":180,"elapsed":8227,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"99c0306b-1305-4176-df5b-284c7ca84457"},"source":["# Carregar modelo\r\n","model = BertForSequenceClassification.from_pretrained(\r\n","    \"pretrained-bert\",\r\n","    num_labels = 2,\r\n","    output_attentions = False, \r\n","    output_hidden_states = False,\r\n",")\r\n","\r\n","# Treinar modelo na GPU\r\n","model.cuda()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at pretrained-bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pretrained-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-B5tw6lreqs_","executionInfo":{"status":"ok","timestamp":1610471351840,"user_tz":180,"elapsed":1406,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["# Instanciar otimizador da descida do gradiente\r\n","optimizer = AdamW(\r\n","  model.parameters(),\r\n","  lr = 2e-3, # taxa de aprendizado\r\n","  eps = 1e-8 # para estabilidade numérica\r\n",")\r\n","\r\n","# Autores recomendam 2-4 épocas (> 2 overfitou)\r\n","epochs = 2\r\n","\r\n","# Número de iterações é [nº de batches] x [nº de épocas]. \r\n","total_steps = len(train_dataloader) * epochs\r\n","\r\n","# Criar scheduler para lr\r\n","scheduler = get_linear_schedule_with_warmup(optimizer, \r\n","                                            num_warmup_steps = 0,\r\n","                                            num_training_steps = total_steps)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZcBp2n9gPxK"},"source":["Antes de treinar, definimos algums funções úteis que serão usadas no processo."]},{"cell_type":"code","metadata":{"id":"zlM63GPae3cU","executionInfo":{"status":"ok","timestamp":1610471367092,"user_tz":180,"elapsed":1049,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}}},"source":["def flat_accuracy(preds, labels):\r\n","  '''\r\n","  Função para calcular acurácia das predições.\r\n","  '''\r\n","  pred_flat = np.argmax(preds, axis=1).flatten()\r\n","  labels_flat = labels.flatten()\r\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n","\r\n","def format_time(elapsed):\r\n","  '''\r\n","  Recebe o tempo em segundos e retorna uma string hh:mm:ss\r\n","  '''\r\n","  elapsed_rounded = int(round((elapsed)))\r\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPiCT-7biMeD"},"source":["Agora estamos prontos para rodar o treinamento.\n","\n","**ATENÇÃO:** evite rodar esta célula caso o modelo já tenha sido treinado! Carregue do arquivo nas próximas células ou re-treine com os melhores hiperparâmetros encontrados. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSFgFIhLgtyU","executionInfo":{"status":"ok","timestamp":1610473444293,"user_tz":180,"elapsed":2075530,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"9a6f3baf-dc0d-407b-b119-84a560b698f3"},"source":["# Tornar treinamento reprodutível\r\n","seed_val = 42\r\n","random.seed(seed_val)\r\n","np.random.seed(seed_val)\r\n","torch.manual_seed(seed_val)\r\n","torch.cuda.manual_seed_all(seed_val)\r\n","\r\n","# Custo, acurácia, tempo...\r\n","training_stats = []\r\n","\r\n","# Tempo total de execução\r\n","total_t0 = time.time()\r\n","\r\n","for epoch_i in range(0, epochs):\r\n","    \r\n","    # ========================================\r\n","    #                 Treino\r\n","    # ========================================\r\n","    # \"Full pass\" no conjunto de treino\r\n","\r\n","    print(\"\")\r\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n","    print('Training...')\r\n","\r\n","    # Quanto dura a época\r\n","    t0 = time.time()\r\n","\r\n","    # Resetar custo\r\n","    total_train_loss = 0\r\n","\r\n","    # Modo de treinamento (não confundir com treinamento em si)\r\n","    model.train()\r\n","\r\n","    for step, batch in enumerate(train_dataloader):\r\n","\r\n","        # Mostrar progresso a cada 40 batches\r\n","        if step % 40 == 0 and not step == 0:\r\n","            elapsed = format_time(time.time() - t0)\r\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\r\n","                step, len(train_dataloader), elapsed))\r\n","\r\n","        # Destacar ids, máscaras e labels do batch\r\n","        b_input_ids = batch[0].to(device)\r\n","        b_input_mask = batch[1].to(device)\r\n","        b_labels = batch[2].to(device=device, dtype=torch.int64)\r\n","\r\n","        # Limpar gradientes\r\n","        model.zero_grad()        \r\n","\r\n","        # \"Forward pass\"\r\n","        loss, logits = model(b_input_ids, \r\n","                             token_type_ids=None, \r\n","                             attention_mask=b_input_mask, \r\n","                             labels=b_labels,\r\n","                             return_dict=False)\r\n","        \r\n","        # Acumular custos para calcular a média\r\n","        total_train_loss += loss.item()\r\n","\r\n","        # \"Backward pass\"\r\n","        loss.backward()\r\n","\r\n","        # Normalizar para evitar com que gradientes explodam\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","        # Atualizar parâmetros\r\n","        optimizer.step()\r\n","        scheduler.step()\r\n","\r\n","    # Calculate the average loss over all of the batches.\r\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \r\n","    \r\n","    # Measure how long this epoch took.\r\n","    training_time = format_time(time.time() - t0)\r\n","\r\n","    print(\"\")\r\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n","    print(\"  Training epcoh took: {:}\".format(training_time))\r\n","        \r\n","    # ========================================\r\n","    #               Validação\r\n","    # ========================================\r\n","    # Medir desempenho no conjunto de validação\r\n","\r\n","    print(\"\")\r\n","    print(\"Running Validation...\")\r\n","\r\n","    # Quanto dura a validação\r\n","    t0 = time.time()\r\n","\r\n","    # Modo de avaliação\r\n","    model.eval()\r\n","\r\n","    # Acumular para todos os batches \r\n","    total_eval_accuracy = 0\r\n","    total_eval_loss = 0\r\n","    nb_eval_steps = 0\r\n","\r\n","    for batch in validation_dataloader:\r\n","        \r\n","        # Destacar ids, máscaras e labels do batch\r\n","        b_input_ids = batch[0].to(device)\r\n","        b_input_mask = batch[1].to(device)\r\n","        b_labels = batch[2].to(device=device, dtype=torch.int64)\r\n","        \r\n","        # Não computar gradientes\r\n","        with torch.no_grad():        \r\n","\r\n","            # Predizer\r\n","            (loss, logits) = model(b_input_ids, \r\n","                                   token_type_ids=None, \r\n","                                   attention_mask=b_input_mask,\r\n","                                   labels=b_labels,\r\n","                                   return_dict=False)\r\n","            \r\n","        # Acumular custo\r\n","        total_eval_loss += loss.item()\r\n","\r\n","        # Mover predições e labels para CPU\r\n","        logits = logits.detach().cpu().numpy()\r\n","        label_ids = b_labels.to('cpu').numpy()\r\n","\r\n","        # Acumular acurácia para esse batch\r\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\r\n","\r\n","    # Acurácia da validação\r\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\r\n","\r\n","    # Média do custo\r\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n","    \r\n","    # Tempo da validação\r\n","    validation_time = format_time(time.time() - t0)\r\n","    \r\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n","    print(\"  Validation took: {:}\".format(validation_time))\r\n","\r\n","    # Armazenar estatísticas\r\n","    training_stats.append(\r\n","        {\r\n","            'epoch': epoch_i + 1,\r\n","            'Training Loss': avg_train_loss,\r\n","            'Valid. Loss': avg_val_loss,\r\n","            'Valid. Accur.': avg_val_accuracy,\r\n","            'Training Time': training_time,\r\n","            'Validation Time': validation_time\r\n","        }\r\n","    )\r\n","\r\n","print(\"\")\r\n","print(\"Training complete!\")\r\n","print(\"Total training took {:} (h:mm:ss)\".format(\r\n","    format_time(time.time()-total_t0)))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch    40  of  1,050.    Elapsed: 0:00:38.\n","  Batch    80  of  1,050.    Elapsed: 0:01:15.\n","  Batch   120  of  1,050.    Elapsed: 0:01:53.\n","  Batch   160  of  1,050.    Elapsed: 0:02:31.\n","  Batch   200  of  1,050.    Elapsed: 0:03:09.\n","  Batch   240  of  1,050.    Elapsed: 0:03:47.\n","  Batch   280  of  1,050.    Elapsed: 0:04:25.\n","  Batch   320  of  1,050.    Elapsed: 0:05:03.\n","  Batch   360  of  1,050.    Elapsed: 0:05:40.\n","  Batch   400  of  1,050.    Elapsed: 0:06:18.\n","  Batch   440  of  1,050.    Elapsed: 0:06:56.\n","  Batch   480  of  1,050.    Elapsed: 0:07:34.\n","  Batch   520  of  1,050.    Elapsed: 0:08:12.\n","  Batch   560  of  1,050.    Elapsed: 0:08:50.\n","  Batch   600  of  1,050.    Elapsed: 0:09:27.\n","  Batch   640  of  1,050.    Elapsed: 0:10:05.\n","  Batch   680  of  1,050.    Elapsed: 0:10:43.\n","  Batch   720  of  1,050.    Elapsed: 0:11:21.\n","  Batch   760  of  1,050.    Elapsed: 0:11:59.\n","  Batch   800  of  1,050.    Elapsed: 0:12:37.\n","  Batch   840  of  1,050.    Elapsed: 0:13:14.\n","  Batch   880  of  1,050.    Elapsed: 0:13:52.\n","  Batch   920  of  1,050.    Elapsed: 0:14:30.\n","  Batch   960  of  1,050.    Elapsed: 0:15:08.\n","  Batch 1,000  of  1,050.    Elapsed: 0:15:46.\n","  Batch 1,040  of  1,050.    Elapsed: 0:16:24.\n","\n","  Average training loss: 0.49\n","  Training epcoh took: 0:16:33\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation Loss: 0.44\n","  Validation took: 0:00:44\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch    40  of  1,050.    Elapsed: 0:00:38.\n","  Batch    80  of  1,050.    Elapsed: 0:01:16.\n","  Batch   120  of  1,050.    Elapsed: 0:01:53.\n","  Batch   160  of  1,050.    Elapsed: 0:02:31.\n","  Batch   200  of  1,050.    Elapsed: 0:03:09.\n","  Batch   240  of  1,050.    Elapsed: 0:03:47.\n","  Batch   280  of  1,050.    Elapsed: 0:04:25.\n","  Batch   320  of  1,050.    Elapsed: 0:05:03.\n","  Batch   360  of  1,050.    Elapsed: 0:05:41.\n","  Batch   400  of  1,050.    Elapsed: 0:06:19.\n","  Batch   440  of  1,050.    Elapsed: 0:06:56.\n","  Batch   480  of  1,050.    Elapsed: 0:07:34.\n","  Batch   520  of  1,050.    Elapsed: 0:08:12.\n","  Batch   560  of  1,050.    Elapsed: 0:08:50.\n","  Batch   600  of  1,050.    Elapsed: 0:09:28.\n","  Batch   640  of  1,050.    Elapsed: 0:10:05.\n","  Batch   680  of  1,050.    Elapsed: 0:10:43.\n","  Batch   720  of  1,050.    Elapsed: 0:11:21.\n","  Batch   760  of  1,050.    Elapsed: 0:11:59.\n","  Batch   800  of  1,050.    Elapsed: 0:12:37.\n","  Batch   840  of  1,050.    Elapsed: 0:13:15.\n","  Batch   880  of  1,050.    Elapsed: 0:13:52.\n","  Batch   920  of  1,050.    Elapsed: 0:14:30.\n","  Batch   960  of  1,050.    Elapsed: 0:15:08.\n","  Batch 1,000  of  1,050.    Elapsed: 0:15:46.\n","  Batch 1,040  of  1,050.    Elapsed: 0:16:24.\n","\n","  Average training loss: 0.38\n","  Training epcoh took: 0:16:33\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation Loss: 0.44\n","  Validation took: 0:00:44\n","\n","Training complete!\n","Total training took 0:34:34 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bUrUWb7eorJ6"},"source":["Para evitar treinar novamente, salvamos o modelo no drive."]},{"cell_type":"code","metadata":{"id":"GLJ3EQ8Wo6iz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610473915811,"user_tz":180,"elapsed":3986,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"dbc1b621-08ef-4c67-ee5a-48ee9620264f"},"source":["output_dir = './trained-bert/'\r\n","\r\n","# Criar pasta se preciso\r\n","if not os.path.exists(output_dir):\r\n","    os.makedirs(output_dir)\r\n","\r\n","print(\"Saving model to %s\" % output_dir)\r\n","\r\n","# Salvar modelo treinado\r\n","model_to_save = model.module if hasattr(model, 'module') else model \r\n","model_to_save.save_pretrained(output_dir)\r\n","tokenizer.save_pretrained(output_dir)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Saving model to ./trained-bert/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./trained-bert/tokenizer_config.json',\n"," './trained-bert/special_tokens_map.json',\n"," './trained-bert/vocab.txt',\n"," './trained-bert/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"P6AvDe44uEoh"},"source":["## **Avaliação**\n","\n","Primeiro, carregamos o modelo salvo na pasta `trained-bert`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeN_T9u4x6kk","executionInfo":{"status":"ok","timestamp":1610475194087,"user_tz":180,"elapsed":5938,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"e8219e43-7066-4e6f-a7dc-2fa54a811b91"},"source":["output_dir = './trained-bert/'\n","\n","# Carregar modelo e vocabulário treinado\n","model = BertForSequenceClassification.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","\n","# Copiar o modelo na GPU\n","model.to(device)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"9t1zImUF5SXh"},"source":["Utilizamos o modelo treinado para computar as predições no conjunto de teste e avaliar como o modelo generaliza."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15XPcpZD2e6G","executionInfo":{"status":"ok","timestamp":1610478408023,"user_tz":180,"elapsed":45254,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"1209fb29-f96b-4f6c-e3ee-2df420151852"},"source":["# Modo de avaliação\n","model.eval()\n","\n","# Armazenar predições \n","predictions , true_labels = [], []\n","\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Destacar ids, máscaras e labels do batch\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  with torch.no_grad():\n","      # \"Forward pass\"\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Mover predições e labels p/ cpu\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Armazenar predições e labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","# Converter predições e labels em arrays com 0s e 1s\n","flat_predictions = np.concatenate(predictions, axis=0)\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Mostrar métricas\n","print(classification_report(flat_true_labels, flat_predictions))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.76      0.80      1219\n","         1.0       0.71      0.83      0.76       881\n","\n","    accuracy                           0.79      2100\n","   macro avg       0.78      0.79      0.78      2100\n","weighted avg       0.80      0.79      0.79      2100\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ccHN6J6N_SKf"},"source":["Finalmente, plotamos a matriz de confusão para termos uma visão melhor dos acertos e erros do modelo treinado."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"vH6J4_60-DEo","executionInfo":{"status":"ok","timestamp":1610478458622,"user_tz":180,"elapsed":1372,"user":{"displayName":"Eduardo Barros Innarelli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-HPBu7P07dv37oyEQB7d3kQqc3oZtuG58DW9x=s64","userId":"06818377933646517062"}},"outputId":"26b5b22b-79d6-4dbf-dd36-e6327867739c"},"source":["# Construir matriz de confusão com scikit-learn\n","cmatrix = confusion_matrix(flat_true_labels, flat_predictions)\n","\n","# Salvar matriz como um dataframe do pandas\n","labels = ['inofensivo', 'tóxico']\n","df_cm = pd.DataFrame(cmatrix, columns=labels, index=labels)\n","df_cm.index.name = 'Real'\n","df_cm.columns.name = 'Previsto'\n","\n","# Plotar como um mapa de calor\n","plt.figure(figsize = (10,7))\n","sns.set(font_scale=1.2)\n","sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 10}, fmt='g');"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}